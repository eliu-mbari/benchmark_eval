{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d972d6f4-b706-45d7-887d-c5f09e845810",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install ultralytics\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "\n",
    "import os\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9584d6af-ec95-48c2-ab81-967f04f77c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTING VARIABLES\n",
    "# video sequence name - options are \"simple_mid\", \"simple_ben\", \"difficult_mid\", \"difficult_ben\"\n",
    "vid_seq_name = \"difficult_mid\"\n",
    "# dimensions of frames\n",
    "img_width, img_height = 1920, 1080\n",
    "\n",
    "# DEFINING FUNCTIONS\n",
    "\n",
    "#tracker paths\n",
    "yolo_labels = \"/Users/eliu/.pyenv/runs/detect/track/labels\"\n",
    "output_mot = \"/Users/eliu/Documents/benchmark_eval/data/trackers/mot_challenge/MOT17-train/YOLOTracker/difficult_mid.txt\"\n",
    "# gt paths\n",
    "# yolo_labels = \"/Users/eliu/Documents/raw_gt/labels\"\n",
    "# output_mot = \"/Users/eliu/Documents/benchmark_eval/data/gt/mot_challenge/MOT17-train/simple_mid_boxmot_bytetrack_tuned3\"\n",
    "def yolo_to_mot():\n",
    "    # unnormalize labels\n",
    "    count = 0\n",
    "    frame_files = sorted(glob.glob(os.path.join(yolo_labels, \"*.txt\")))\n",
    "    with open(output_mot, \"w\") as out_file:\n",
    "        for file in frame_files:\n",
    "            name = os.path.basename(file).split(\".\")[0]\n",
    "            frame_idx = int(name.split(\"_\")[-1])\n",
    "            with open(file, \"r\") as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) != 6:\n",
    "                        print(f\"Skipping line in {file}: {line.strip()}\")\n",
    "                        count = count + 1\n",
    "                        continue\n",
    "                    class_id, x_center, y_center, width, height, track_id = map(float, line.strip().split())\n",
    "                    #calculate\n",
    "                    x = (x_center - width / 2) * img_width\n",
    "                    y = (y_center - height / 2) * img_height\n",
    "                    w = width * img_width\n",
    "                    h = height * img_height\n",
    "\n",
    "                    out_file.write(f\"{frame_idx}, {int(track_id)}, {x:.2f}, {y:.2f}, {w:.2f}, {h:.2f}, 1, 1, -1\\n\")\n",
    "    print(\"number of skipped lines: \", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e9b45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING ⚠️ \n",
      "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/600) /Users/eliu/Documents/videos/difficult_ben/Benthic_1_V4277_20200219T211238Z.mov: 736x1280 16 Funiculina-Balticina complexs, 1 Umbellula, 203.6ms\n",
      "video 1/1 (frame 2/600) /Users/eliu/Documents/videos/difficult_ben/Benthic_1_V4277_20200219T211238Z.mov: 736x1280 16 Funiculina-Balticina complexs, 1 Umbellula, 106.2ms\n",
      "video 1/1 (frame 3/600) /Users/eliu/Documents/videos/difficult_ben/Benthic_1_V4277_20200219T211238Z.mov: 736x1280 26 Funiculina-Balticina complexs, 1 Umbellula, 107.2ms\n",
      "video 1/1 (frame 4/600) /Users/eliu/Documents/videos/difficult_ben/Benthic_1_V4277_20200219T211238Z.mov: 736x1280 28 Funiculina-Balticina complexs, 107.4ms\n",
      "video 1/1 (frame 5/600) /Users/eliu/Documents/videos/difficult_ben/Benthic_1_V4277_20200219T211238Z.mov: 736x1280 26 Funiculina-Balticina complexs, 1 Umbellula, 105.8ms\n",
      "video 1/1 (frame 6/600) /Users/eliu/Documents/videos/difficult_ben/Benthic_1_V4277_20200219T211238Z.mov: 736x1280 27 Funiculina-Balticina complexs, 1 Sebastolobus, 1 Umbellula, 109.0ms\n",
      "video 1/1 (frame 7/600) /Users/eliu/Documents/videos/difficult_ben/Benthic_1_V4277_20200219T211238Z.mov: 736x1280 27 Funiculina-Balticina complexs, 1 Umbellula, 107.9ms\n",
      "video 1/1 (frame 8/600) /Users/eliu/Documents/videos/difficult_ben/Benthic_1_V4277_20200219T211238Z.mov: 736x1280 29 Funiculina-Balticina complexs, 1 Sebastolobus, 1 Umbellula, 108.0ms\n",
      "video 1/1 (frame 9/600) /Users/eliu/Documents/videos/difficult_ben/Benthic_1_V4277_20200219T211238Z.mov: 736x1280 29 Funiculina-Balticina complexs, 1 Sebastolobus, 1 Umbellula, 107.7ms\n",
      "video 1/1 (frame 10/600) /Users/eliu/Documents/videos/difficult_ben/Benthic_1_V4277_20200219T211238Z.mov: 736x1280 29 Funiculina-Balticina complexs, 1 Sebastolobus, 1 Umbellula, 107.5ms\n",
      "video 1/1 (frame 11/600) /Users/eliu/Documents/videos/difficult_ben/Benthic_1_V4277_20200219T211238Z.mov: 736x1280 29 Funiculina-Balticina complexs, 1 Sebastolobus, 1 Umbellula, 107.4ms\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/eliu/Desktop/mbari_452k_yolov8.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# vid_path = \"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# #change video path\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# if vid_seq_name == \"simple_mid\":\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# elif vid_seq_name == \"difficult_ben\":\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#     vid_path = \"/Users/eliu/Documents/videos/difficult_ben/Benthic_1_V4277_20200219T211238Z.mov\"\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/eliu/Documents/videos/difficult_ben/Benthic_1_V4277_20200219T211238Z.mov\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtracker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/eliu/Desktop/bytetrack_kwalz_settings.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# tracker=\"bytetrack.yaml\", \u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m                \u001b[49m\u001b[43mline_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                \u001b[49m\u001b[43magnostic_nms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m#save_crop=True,\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m#save_conf=True,\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m                \u001b[49m\u001b[43msave_txt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m#save_frames=True,\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.025\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                \u001b[49m\u001b[43miou\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                \u001b[49m\u001b[43mhalf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m#vid_stride=60,\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m#show=True,\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m#visualize=True,\u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m#stream=True,\u001b[39;49;00m\n\u001b[1;32m     33\u001b[0m \u001b[43m                \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1280\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     35\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/trackeval-env/lib/python3.10/site-packages/ultralytics/engine/model.py:599\u001b[0m, in \u001b[0;36mModel.track\u001b[0;34m(self, source, stream, persist, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# batch-size 1 for tracking in videos\u001b[39;00m\n\u001b[1;32m    598\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrack\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/trackeval-env/lib/python3.10/site-packages/ultralytics/engine/model.py:555\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[0;32m--> 555\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/trackeval-env/lib/python3.10/site-packages/ultralytics/engine/predictor.py:227\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/trackeval-env/lib/python3.10/site-packages/torch/utils/_contextlib.py:57\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m             \u001b[38;5;66;03m# Pass the last request to the generator and get its response\u001b[39;00m\n\u001b[1;32m     56\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 57\u001b[0m                 response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# We let the exceptions raised above by the generator's `.throw` or\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# `.send` methods bubble up to our caller, except for StopIteration\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# The generator informed us that it is done: take whatever its\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# returned value (if any) was and indicate that we're done too\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# by returning it (see docs for python's return-statement).\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/trackeval-env/lib/python3.10/site-packages/ultralytics/engine/predictor.py:337\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# Postprocess\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m2\u001b[39m]:\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim0s\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_predict_postprocess_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;66;03m# Visualize, save, write results\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/trackeval-env/lib/python3.10/site-packages/ultralytics/models/yolo/detect/predict.py:56\u001b[0m, in \u001b[0;36mDetectionPredictor.postprocess\u001b[0;34m(self, preds, img, orig_imgs, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03mPost-process predictions and return a list of Results objects.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    >>> processed_results = predictor.postprocess(preds, img, orig_imgs)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     55\u001b[0m save_feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_feats\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnon_max_suppression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miou\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magnostic_nms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_det\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_det\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdetect\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend2end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend2end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrotated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_idxs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_feats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(orig_imgs, \u001b[38;5;28mlist\u001b[39m):  \u001b[38;5;66;03m# input images are a torch.Tensor, not a list\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     orig_imgs \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_torch2numpy_batch(orig_imgs)\n",
      "File \u001b[0;32m~/.pyenv/versions/trackeval-env/lib/python3.10/site-packages/ultralytics/utils/ops.py:310\u001b[0m, in \u001b[0;36mnon_max_suppression\u001b[0;34m(prediction, conf_thres, iou_thres, classes, agnostic, multi_label, labels, max_det, nc, max_time_img, max_nms, max_wh, in_place, rotated, end2end, return_idxs)\u001b[0m\n\u001b[1;32m    307\u001b[0m     xk \u001b[38;5;241m=\u001b[39m xk[filt]\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# Filter by class\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m classes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     filt \u001b[38;5;241m=\u001b[39m (x[:, \u001b[38;5;241m5\u001b[39m:\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m==\u001b[39m classes)\u001b[38;5;241m.\u001b[39many(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    312\u001b[0m     x, xk \u001b[38;5;241m=\u001b[39m x[filt], xk[filt]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# MODEL + TRACKER\n",
    "from ultralytics import YOLO\n",
    "# Load a model\n",
    "model = YOLO('/Users/eliu/Desktop/mbari_452k_yolov8.pt')\n",
    "# vid_path = \"\"\n",
    "# #change video path\n",
    "# if vid_seq_name == \"simple_mid\":\n",
    "#     vid_path = \"/Users/eliu/Documents/videos/simple_mid/Midwater_simple_V4455_20221130T192123Z_prores.mov\"\n",
    "# elif vid_seq_name == \"simple_ben\":\n",
    "#     vid_path = \"/Users/eliu/Documents/videos/simple_ben/10s_Benthic_2_V4289_20200729T185027Z.mov\"\n",
    "# elif vid_seq_name == \"difficult_mid\":\n",
    "#     vid_path = \"/Users/eliu/Documents/videos/difficult_mid/Midwater_difficult_V4432_20220914T160635Z_prores.mov\"\n",
    "# elif vid_seq_name == \"difficult_ben\":\n",
    "#     vid_path = \"/Users/eliu/Documents/videos/difficult_ben/Benthic_1_V4277_20200219T211238Z.mov\"\n",
    "results = model.track(source=\"/Users/eliu/Documents/videos/difficult_ben/Benthic_1_V4277_20200219T211238Z.mov\",\n",
    "                tracker=\"/Users/eliu/Desktop/bytetrack_kwalz_settings.yaml\",\n",
    "                # tracker=\"bytetrack.yaml\", \n",
    "                line_width=1,\n",
    "                agnostic_nms=True,\n",
    "                #save_crop=True,\n",
    "                #save_conf=True,\n",
    "                save_txt=True,\n",
    "                save=True,\n",
    "                #save_frames=True,\n",
    "                conf=0.025,\n",
    "                iou=0.4,\n",
    "                half=True,\n",
    "                device='mps',\n",
    "                #vid_stride=60,\n",
    "                #show=True,\n",
    "                #visualize=True,\n",
    "                #stream=True,\n",
    "                imgsz=1280\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443150f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUND TRUTH - adding track id to exported gt yolo txt files\n",
    "import os\n",
    "\n",
    "#paths\n",
    "input_folder = \"/Users/eliu/Documents/raw_gt/labels\"\n",
    "output_folder = \"/Users/eliu/Documents/raw_gt/labels_w_trackid\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "#get all name files\n",
    "name_files = [f for f in os.listdir(input_folder) if f.endswith(\"_name.txt\")]\n",
    "for name_file in name_files:\n",
    "    #paths\n",
    "    base_file = name_file.replace(\"_name\", \"\")\n",
    "    name_file_path = os.path.join(input_folder, name_file)\n",
    "    base_file_path = os.path.join(input_folder, base_file)\n",
    "    output_file_path = os.path.join(output_folder, base_file)\n",
    "\n",
    "    # reading files\n",
    "    with open(name_file_path, \"r\") as f_name, open(base_file_path, \"r\") as f_base:\n",
    "        name_lines = f_name.readlines()\n",
    "        base_lines = f_base.readlines()\n",
    "\n",
    "    #make new files\n",
    "    with open(output_file_path, \"w\") as f_out:\n",
    "        for base_line, name_line in zip(base_lines, name_lines):\n",
    "            if base_line.strip() and name_line.strip():\n",
    "                # get track id\n",
    "                track_id = int(name_line.strip().rsplit(\"-\", 1)[-1])\n",
    "                # combine line + track id\n",
    "                f_out.write(base_line.strip() + f\" {track_id}\\n\")\n",
    "\n",
    "#Converting format\n",
    "yolo_to_mot()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m109"
  },
  "kernelspec": {
   "display_name": "trackeval-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
